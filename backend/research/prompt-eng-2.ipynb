{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "OLLAMA_BASE_URL=\"https://61d7-107-20-19-92.ngrok-free.app\"\n",
    "OLLAMA_MODEL=\"llama3\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "llm = ChatOllama(model=OLLAMA_MODEL, base_url=OLLAMA_BASE_URL, format=\"json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role play Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\" You are an expert at generating role play conversations in {language} \\\n",
    "Given an input phrase in {language}, you generate a role play conversation in {language}\\\n",
    "between two participants with the following in JSON format: \\\n",
    "\n",
    "Background: A short description of the a role play scenario in {language}. Maximum {max_words} words. \\\n",
    "<Name of First Participant>: Statement made to the second particpant in {language}. Maximum {max_words} words\\\n",
    "<Name of Second participant>: Response to the first participant in {language}, Maximum {max_words} words. \\\n",
    "\"\"\"\n",
    "\n",
    "human_prompt = \"phrase: {phrase}\"\n",
    "\n",
    "role_play_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", human_prompt),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "async def generate_roleplay(language: str, phrase: str, max_words: int):\n",
    "    all_chunks = []\n",
    "    display_frequency = 20\n",
    "\n",
    "    chain = role_play_prompt | llm | StrOutputParser()\n",
    "\n",
    "    async for chunk in chain.astream({\"language\": language, \n",
    "                                    \"phrase\": phrase,\n",
    "                                    \"max_words\": max_words\n",
    "                                    }):\n",
    "        all_chunks.append(chunk)\n",
    "        # print just to confirm that llm is working\n",
    "        if len(all_chunks) % display_frequency == 0:\n",
    "            print(chunk)\n",
    "    \n",
    "    return \"\".join(all_chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ise\n",
      " der\n",
      " Berlin\n",
      "bah\n",
      "indr\n",
      "******Generated Role Play ******\n",
      "{ \"Background\": \"Eine Gruppe von Freunden plaudert über ihre letzte Reise nach Berlin.\",\n",
      "\"Max Mustermann\": \"Ich bin immer noch geschockt darüber, dass der Hauptbahnhof so unglaublich groß ist! Ich dachte, ich kenne Berlin, aber das war ein Schock für mich.\",\n",
      "\"Laura Mayer\": \"Ja, der Hauptbahnhof ist tatsächlich beeindruckend. Aber was hat dich am meisten beeindruckt an deiner Reise? Die Museen oder die Straßen?\" }\n"
     ]
    }
   ],
   "source": [
    "language = \"German\"\n",
    "phrase = \"unglaublich\"\n",
    "max_words = 25\n",
    "\n",
    "response = await generate_roleplay(language, phrase, max_words)\n",
    "print(\"******Generated Role Play ******\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Background': 'Eine Gruppe von Freunden plaudert über ihre letzte Reise nach Berlin.',\n",
       " 'Max Mustermann': 'Ich bin immer noch geschockt darüber, dass der Hauptbahnhof so unglaublich groß ist! Ich dachte, ich kenne Berlin, aber das war ein Schock für mich.',\n",
       " 'Laura Mayer': 'Ja, der Hauptbahnhof ist tatsächlich beeindruckend. Aber was hat dich am meisten beeindruckt an deiner Reise? Die Museen oder die Straßen?'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_json = json.loads(response)\n",
    "response_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Translate Roleplay Prompt to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\" You are an expert Translator from any language to English \\\n",
    "Given a JSON dictionary, return a JSON with translated dictionary values.\n",
    "\"\"\"\n",
    "human_prompt = \"\"\"\n",
    "dictionary: {dictionary}\n",
    "\"\"\"\n",
    "\n",
    "translation_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", human_prompt),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "async def generate_translation(dictionary: dict):\n",
    "    all_chunks = []\n",
    "    display_frequency = 20\n",
    "\n",
    "    chain = translation_prompt | llm | StrOutputParser()\n",
    "\n",
    "    async for chunk in chain.astream({\"dictionary\": dictionary}):\n",
    "        all_chunks.append(chunk)\n",
    "        # print just to confirm that llm is working\n",
    "        if len(all_chunks) % display_frequency == 0:\n",
    "            print(chunk)\n",
    "    \n",
    "    return \"\".join(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max\n",
      " I\n",
      " the\n",
      " streets\n",
      "{ \"Background\": \"A group of friends are chatting about their latest trip to Berlin.\",\n",
      "\"Max Mustermann\": \"I'm still shocked that the main station is so incredibly huge! I thought I knew Berlin, but it was a shock for me.\", \n",
      "\"Laura Mayer\": \"Yes, the main station is indeed impressive. But what impressed you most on your trip? The museums or the streets?\" }\n"
     ]
    }
   ],
   "source": [
    "translated_response = await generate_translation(response)\n",
    "print(translated_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Background': 'A group of friends are chatting about their latest trip to Berlin.',\n",
       " 'Max Mustermann': \"I'm still shocked that the main station is so incredibly huge! I thought I knew Berlin, but it was a shock for me.\",\n",
       " 'Laura Mayer': 'Yes, the main station is indeed impressive. But what impressed you most on your trip? The museums or the streets?'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translated_response_json = json.loads(translated_response)\n",
    "translated_response_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "research-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
